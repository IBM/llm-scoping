{
"program": "~/steering_hierarchy/dpo.py",
"args": {
"ndevices": 1,
"per_device_train_batch_size": 1,
"gradient_accumulation_steps": 16,
"lora_rank": 16,
"num_steps": 512,
"accept_dsets": "sni_s",
"reject_dsets": [
"sni_sa,sni_tld,sni_pe,sni_tc,sni_sc,sni_dg"
],
"num_prompts_per_dset": 2048,
"model": ["mistral", "granite"],
"system_prompt": true
}
}
